{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Classification - Health Insurance Cross Sell Prediction**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 - Gautam Verma**\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Project Summary: Insurance Cross-Sell Prediction\n",
        "The goal of this project is to predict the likelihood of existing insurance customers purchasing a vehicle insurance policy using machine learning techniques. The dataset includes 12 columns, such as Gender, Age, Driving_License, Region_Code, Previously_Insured, Vehicle_Age, Vehicle_Damage, Annual_Premium, Policy_Sales_Channel, Vintage, and Response, with Response being the target variable indicating whether a customer purchased the vehicle insurance.\n",
        "\n",
        "Data Exploration and Preprocessing:\n",
        "The initial exploration of the data involved understanding the distribution and relationships within the dataset. Key preprocessing steps included handling missing values and encoding categorical variables. Categorical variables such as Gender, Vehicle_Age, and Vehicle_Damage were label-encoded, while variables like Region_Code and Policy_Sales_Channel were one-hot encoded to ensure compatibility with machine learning algorithms. Numerical features were standardized to bring all variables to a comparable scale.\n",
        "\n",
        "Exploratory Data Analysis (EDA):\n",
        "EDA was conducted using visualizations to identify trends and patterns within the data. Histograms, bar charts, and heatmaps were used to visualize the distributions and correlations. Notable observations included:\n",
        "\n",
        "Customers with Previously_Insured status were less likely to purchase vehicle insurance, which was confirmed through the Chi-square test of independence.\n",
        "Significant variation in Annual_Premium across different Region_Code values, justifying the need for feature engineering and hypothesis testing.\n",
        "Hypothesis Testing:\n",
        "A Chi-square test of independence was employed to examine the relationship between categorical variables such as Previously_Insured and Response. This test confirmed a significant association between the insurance status of customers and their likelihood of purchasing vehicle insurance, guiding feature selection for the predictive model.\n",
        "\n",
        "Feature Engineering:\n",
        "To enhance model performance, categorical data was encoded into numerical formats. Label encoding and one-hot encoding were applied as appropriate. This transformation ensured that the machine learning algorithms could effectively process and interpret the data.\n",
        "\n",
        "Model Development:\n",
        "Several machine learning models were developed and evaluated, including Logistic Regression, KMeans Clustering, and Random Forest Classifier. The dataset was split into training and testing sets to evaluate the performance of each model. Performance metrics such as accuracy, precision, recall, and F1-score were utilized to assess the effectiveness of the models. Hyperparameter tuning techniques, including grid search and random search, were employed to optimize model parameters and improve performance.\n",
        "\n",
        "Results:\n",
        "The Random Forest Classifier achieved the highest performance, with significant improvements observed after hyperparameter tuning. The Logistic Regression model also provided valuable insights due to its interpretability, while KMeans Clustering was explored for customer segmentation, offering a different perspective on the data.\n",
        "\n",
        "Conclusion:\n",
        "This project successfully developed a predictive model for insurance cross-sell, leveraging machine learning to identify key factors influencing customer decisions. The findings can help the insurance company strategically target potential customers, enhancing cross-selling opportunities and overall profitability. Future work could involve incorporating additional features, such as customer interaction data, and exploring more advanced modeling techniques to further refine the predictions and improve the model's accuracy."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**\n",
        "\n",
        "The objective of this project is to predict whether existing insurance customers will purchase a vehicle insurance policy. Utilizing a dataset containing customer demographics, policy details, and previous insurance status, the project involves data preprocessing, feature engineering, and developing predictive models. By applying Logistic Regression, Random Forest Classifier, and KMeans Clustering, and using hyperparameter tuning, the goal is to enhance prediction accuracy and help the insurance company effectively target potential buyers, thereby improving cross-selling opportunities."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objs as go\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/TRAIN-HEALTH INSURANCE CROSS SELL PREDICTION.csv')"
      ],
      "metadata": {
        "id": "Qpv6-4XDzOcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop('id',axis=1)"
      ],
      "metadata": {
        "id": "AtrQAMbS0lQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(df.shape)\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.plot(df.isnull().sum(),color='r')"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains 381,109 entries with 11 columns, including customer demographics, policy details, and previous insurance status. It features a mix of categorical and numerical data types, with no missing values, and is ready for preprocessing and analysis for predicting vehicle insurance purchase responses."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "fig = make_subplots(rows=1, cols=2)\n",
        "\n",
        "traces = [\n",
        "    go.Bar(\n",
        "        x=['Male', 'Female'],\n",
        "        y=[\n",
        "            len(df[df['Gender']=='Male']),\n",
        "            len(df[df['Gender']=='Female'])\n",
        "        ],\n",
        "        name='Train Gender',\n",
        "        text = [\n",
        "            str(round(100 * len(df[df['Gender']=='Male']) / len(df), 2)) + '%',\n",
        "            str(round(100 * len(df[df['Gender']=='Female']) / len(df), 2)) + '%'\n",
        "        ],\n",
        "        textposition='auto'\n",
        "    )\n",
        "\n",
        "]\n",
        "\n",
        "for i in range(len(traces)):\n",
        "    fig.append_trace(\n",
        "        traces[i],\n",
        "        (i // 2) + 1,\n",
        "        (i % 2)  +1\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text=' gender column',\n",
        "    height=400,\n",
        "    width=700\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a grouped bar chart to visualize the distribution of gender in the dataset. This chart allows for a clear comparison between male and female counts, providing insight into gender proportions. Additionally, the text annotations provide precise percentage information, enhancing interpretability and understanding of the data."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart reveals that the dataset is slightly skewed towards males, comprising 54.08% of the data, while females represent 45.92%. This insight indicates a relatively balanced distribution of gender, enabling gender-based analysis and potentially uncovering gender-specific patterns or trends within the dataset."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "fig = make_subplots(rows=1, cols=2)\n",
        "\n",
        "traces = [\n",
        "    go.Bar(\n",
        "        x=['Yes', 'No'],\n",
        "        y=[\n",
        "            len(df[df['Driving_License']==1]),\n",
        "            len(df[df['Driving_License']==0])\n",
        "        ],\n",
        "        name='Train Driving_License',\n",
        "        text = [\n",
        "            str(round(100 * len(df[df['Driving_License']==1]) / len(df), 2)) + '%',\n",
        "            str(round(100 * len(df[df['Driving_License']==0]) / len(df), 2)) + '%'\n",
        "        ],\n",
        "        textposition='auto'\n",
        "    )\n",
        "]\n",
        "for i in range(len(traces)):\n",
        "   fig.append_trace(\n",
        "        traces[i],\n",
        "        (i // 2) + 1,\n",
        "        (i % 2)  +1\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text='Train Driving_License column',\n",
        "    height=400,\n",
        "    width=700\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected a grouped bar chart to illustrate the distribution of driving licenses within the dataset. This visualization effectively compares the counts of individuals with and without driving licenses, providing insight into the prevalence of driving licenses among the dataset. Additionally, the percentage annotations enhance understanding by quantifying the proportion of each category"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart indicates that the overwhelming majority of individuals in the dataset possess a driving license, accounting for 99.79% of the data. Conversely, only a small fraction, 0.21%, do not have a driving license. This insight highlights the dataset's strong bias towards individuals with driving licenses, which may impact analysis and modeling.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "fig = make_subplots(rows=1, cols=2)\n",
        "\n",
        "traces = [\n",
        "    go.Bar(\n",
        "        x=['Yes', 'No'],\n",
        "        y=[\n",
        "            len(df[df['Previously_Insured']==1]),\n",
        "            len(df[df['Previously_Insured']==0])\n",
        "        ],\n",
        "        name='Train Previously_Insured',\n",
        "        text = [\n",
        "            str(round(100 * len(df[df['Previously_Insured']==1]) / len(df), 2)) + '%',\n",
        "            str(round(100 * len(df[df['Previously_Insured']==0]) / len(df), 2)) + '%'\n",
        "        ],\n",
        "        textposition='auto'\n",
        "    )\n",
        "]\n",
        "for i in range(len(traces)):\n",
        "    fig.append_trace(\n",
        "        traces[i],\n",
        "        (i // 2) + 1,\n",
        "        (i % 2)  +1\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text='Train Previously_Insured column',\n",
        "    height=400,\n",
        "    width=700\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a grouped bar chart to visualize the distribution of individuals based on their insurance status (previously insured or not). This chart effectively compares the counts of individuals in each category, providing insight into the prevalence of insurance coverage within the dataset. The percentage annotations further enhance understanding by quantifying the proportion of each category."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart reveals that approximately 45.82% of individuals in the dataset were previously insured, while approximately 54.18% were not previously insured. This insight underscores the dataset's relatively balanced distribution of insurance status, suggesting potential opportunities for analyzing and targeting both previously insured and uninsured segments in insurance marketing strategies."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "fig = make_subplots(rows=1, cols=2)\n",
        "\n",
        "traces = [\n",
        "    go.Bar(\n",
        "        x=['Yes', 'No'],\n",
        "        y=[\n",
        "            len(df[df['Vehicle_Damage']=='Yes']),\n",
        "            len(df[df['Vehicle_Damage']=='No'])\n",
        "        ],\n",
        "        name='Train Vehicle_Damage',\n",
        "        text = [\n",
        "            str(round(100 * len(df[df['Vehicle_Damage']=='Yes']) / len(df), 2)) + '%',\n",
        "            str(round(100 * len(df[df['Vehicle_Damage']=='No']) / len(df), 2)) + '%'\n",
        "        ],\n",
        "        textposition='auto'\n",
        "    )\n",
        "]\n",
        "for i in range(len(traces)):\n",
        "    fig.append_trace(\n",
        "        traces[i],\n",
        "        (i // 2) + 1,\n",
        "        (i % 2)  + 1\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text='Train Vehicle_Damage column',\n",
        "    height=400,\n",
        "    width=700\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I selected a grouped bar chart to visualize the distribution of individuals based on whether their vehicle had previous damage or not. This chart effectively compares the counts of individuals in each category, providing insight into the prevalence of vehicle damage within the dataset. Additionally, the percentage annotations enhance understanding by quantifying the proportion of each category."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart illustrates that approximately 50.49% of individuals in the dataset had previous vehicle damage, while approximately 49.51% did not. This insight suggests a relatively balanced distribution of vehicle damage status among the dataset, implying that both categories are well-represented for analysis and modeling purposes."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "fig = make_subplots(rows=1, cols=2)\n",
        "\n",
        "traces = [\n",
        "    go.Bar(\n",
        "        x=['> 2 Years', '1-2 Year', '< 1 Year'],\n",
        "        y=[\n",
        "            len(df[df['Vehicle_Age']=='> 2 Years']),\n",
        "            len(df[df['Vehicle_Age']=='1-2 Year']),\n",
        "            len(df[df['Vehicle_Age']=='< 1 Year'])\n",
        "        ],\n",
        "        name='Train Vehicle_Age',\n",
        "        text = [\n",
        "            str(round(100 * len(df[df['Vehicle_Age']=='> 2 Years']) / len(df), 2)) + '%',\n",
        "            str(round(100 * len(df[df['Vehicle_Age']=='1-2 Year']) / len(df), 2)) + '%',\n",
        "            str(round(100 * len(df[df['Vehicle_Age']=='< 1 Year']) / len(df), 2)) + '%'\n",
        "        ],\n",
        "        textposition='auto'\n",
        "    )\n",
        "]\n",
        "for i in range(len(traces)):\n",
        "    fig.append_trace(\n",
        "        traces[i],\n",
        "        (i // 2) + 1,\n",
        "        (i % 2)  + 1\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text='Train Vehicle_Age column',\n",
        "    height=400,\n",
        "    width=700\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "fig = make_subplots(rows=1, cols=2)\n",
        "\n",
        "traces = [\n",
        "    go.Histogram(\n",
        "        x=df['Age'],\n",
        "        name='Train Age'\n",
        "    )\n",
        "]\n",
        "\n",
        "for i in range(len(traces)):\n",
        "    fig.append_trace(\n",
        "        traces[i],\n",
        "        (i // 2) + 1,\n",
        "        (i % 2)  + 1\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text='Train Age column distribution',\n",
        "    height=500,\n",
        "    width=900\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram of age distribution indicates that the highest frequency of individuals occurs around the age of 24, with approximately 25.96k occurrences. The frequency then gradually decreases until age 36, where it drops to 5066 occurrences. Subsequently, there is a slight increase in frequency until around age 47, with approximately 8437 occurrences, followed by a significant decrease towards the age of 80, which has the lowest frequency of 909 occurrences. This insight suggests a non-linear distribution of age within the dataset, with certain age groups being more prevalent than others."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "\n",
        "\n",
        "fig = px.histogram(df, x='Annual_Premium', title='Annual Premium Distribution',\n",
        "                   labels={'Annual_Premium': 'Annual Premium'}, nbins=50, height=500, width=800)\n",
        "\n",
        "# Update layout for better fitting\n",
        "fig.update_layout(\n",
        "    xaxis_title='Annual Premium',\n",
        "    yaxis_title='Count',\n",
        "    bargap=0.1,  # Adjusts the gap between bars\n",
        "    title_x=0.5  # Centers the title\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "metadata": {
        "id": "nCFAeSup4WBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "fig = go.Figure(data=[go.Histogram(x=df['Vintage'])])\n",
        "\n",
        "# Update layout for better readability\n",
        "fig.update_layout(\n",
        "    title='Distribution of Vintage',\n",
        "    xaxis_title='Vintage',\n",
        "    yaxis_title='Count',\n",
        "    bargap=0.2\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "region_counts = df['Region_Code'].value_counts().reset_index()\n",
        "region_counts.columns = ['Region_Code', 'Count']\n",
        "\n",
        "# Create a bar chart for the Region_Code column\n",
        "fig = go.Figure(data=[\n",
        "    go.Bar(x=region_counts['Region_Code'], y=region_counts['Count'])\n",
        "])\n",
        "\n",
        "# Update layout for better readability\n",
        "fig.update_layout(\n",
        "    title='Distribution of Region_Code',\n",
        "    xaxis_title='Region Code',\n",
        "    yaxis_title='Count',\n",
        "    bargap=0.2\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "fig = px.histogram(\n",
        "    df,\n",
        "    \"Age\",\n",
        "    color='Response',\n",
        "    nbins=100,\n",
        "    title='Age & Response ditribution',\n",
        "    width=700,\n",
        "    height=500\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "\n",
        "fig = px.histogram(\n",
        "    df[df['Response'] == 1],\n",
        "    \"Age\",\n",
        "    nbins=100,\n",
        "    title='Age distribution for positive response',\n",
        "    width=700,\n",
        "    height=500\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "gender_response_counts = df.groupby(['Gender', 'Response']).size().reset_index(name='Count')\n",
        "\n",
        "# Create separate dataframes for each response type\n",
        "response_0 = gender_response_counts[gender_response_counts['Response'] == 0]\n",
        "response_1 = gender_response_counts[gender_response_counts['Response'] == 1]\n",
        "\n",
        "# Create a grouped bar chart for the Gender/Response dependencies\n",
        "fig = go.Figure(data=[\n",
        "    go.Bar(name='Response: 0', x=response_0['Gender'], y=response_0['Count']),\n",
        "    go.Bar(name='Response: 1', x=response_1['Gender'], y=response_1['Count'])\n",
        "])\n",
        "\n",
        "# Update layout for better readability\n",
        "fig.update_layout(\n",
        "    title='Gender vs. Response Distribution',\n",
        "    xaxis_title='Gender',\n",
        "    yaxis_title='Count',\n",
        "    barmode='group'  # Group bars together\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected a grouped bar chart to visualize the distribution of responses (0 and 1) across different genders. This chart effectively compares the counts of responses for each gender category, providing insight into the relationship between gender and response. The grouped bars allow for easy comparison between response categories within each gender group, facilitating interpretation of any gender-related patterns in the response data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart reveals that among females, there are approximately 156.835k responses labeled as 0 and 18.185k responses labeled as 1. For males, approximately 177.564k responses are labeled as 0, while 28.525k responses are labeled as 1. This insight indicates that both genders have a higher count of responses labeled as 0 compared to 1, with males having a slightly higher count of response labeled as 1 compared to females."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "\n",
        "fig = px.histogram(\n",
        "    df,\n",
        "    \"Annual_Premium\",\n",
        "    color='Response',\n",
        "    nbins=100,\n",
        "    title='Annual_Premium & Response ditribution',\n",
        "    width=700,\n",
        "    height=500\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Chart 14\n",
        "\n",
        "fig = px.histogram(\n",
        "    df,\n",
        "    \"Vintage\",\n",
        "    color='Response',\n",
        "    nbins=100,\n",
        "    title='Vintage & Response ditribution',\n",
        "    width=700,\n",
        "    height=500\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "hSv9Xnyv5wrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "078BIcnQdp7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Categorical Encoding"
      ],
      "metadata": {
        "id": "aeb8713sd0y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding Categorical Data\n",
        "df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})\n",
        "df['Vehicle_Age'] = df['Vehicle_Age'].map({'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2})\n",
        "df['Vehicle_Damage'] = df['Vehicle_Damage'].map({'No': 0, 'Yes': 1})"
      ],
      "metadata": {
        "id": "5fyMDESWdphc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart -15 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Create a heatmap using Plotly Express\n",
        "fig = px.imshow(correlation_matrix,\n",
        "                labels=dict(x=\"Features\", y=\"Features\", color=\"Correlation\"),\n",
        "                x=correlation_matrix.columns,\n",
        "                y=correlation_matrix.columns,\n",
        "                color_continuous_scale='Viridis')\n",
        "\n",
        "# Update layout for better readability\n",
        "fig.update_layout(\n",
        "    title='Correlation Heatmap',\n",
        "    xaxis_title='Features',\n",
        "    yaxis_title='Features'\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns:\n",
        "    if col == 'Response':\n",
        "        continue\n",
        "    print(col, df[col].corr(df['Response']))"
      ],
      "metadata": {
        "id": "0e_cJnIQ6hN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correlation analysis between independent variables and the response variable 'Response' reveals the following insights:\n",
        "\n",
        "**Gender**: There is a weak negative correlation (-0.0524) between gender and response, indicating a slight tendency for different response rates between genders.\n",
        "\n",
        "**Age**: There is a positive correlation (0.1111) between age and response, suggesting that older individuals may be more likely to respond positively.\n",
        "\n",
        "**Driving_License**: There is a very weak positive correlation (0.0102) between having a driving license and response.\n",
        "\n",
        "**Region_Code**: There is a very weak positive correlation (0.0106) between region code and response.\n",
        "\n",
        "**Previously_Insured**: There is a moderate negative correlation (-0.3412) between previous insurance status and response, indicating that individuals without prior insurance are more likely to respond positively.\n",
        "\n",
        "**Vehicle_Age**: There is a moderate positive correlation (0.2219) between vehicle age and response, suggesting that individuals with older vehicles may be more likely to respond positively.\n",
        "\n",
        "**Vehicle_Damage**: There is a strong positive correlation (0.3544) between vehicle damage status and response, indicating that individuals with prior vehicle damage are more likely to respond positively.\n",
        "\n",
        "**Annual_Premium**: There is a very weak positive correlation (0.0226) between annual premium and response.\n",
        "\n",
        "**Policy_Sales_Channel**: There is a moderate negative correlation (-0.1390) between policy sales channel and response, suggesting that certain sales channels may be associated with higher response rates.\n",
        "\n",
        "**Vintage**: There is a very weak negative correlation (-0.0011) between customer vintage (number of days with the company) and response, indicating little to no relationship between vintage and response."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Scatter Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig = px.scatter(\n",
        "    df,\n",
        "    x=\"Annual_Premium\",\n",
        "    y=\"Age\",\n",
        "    color=\"Response\",\n",
        "    width=600,\n",
        "    height=600,\n",
        "    title='Annual_premium vs Age scatter'\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a scatter plot to visualize the relationship between annual premium and age while differentiating responses with different colors. This chart allows for the examination of potential patterns or clusters in the data based on these two continuous variables and how they relate to the response variable. Additionally, the use of color distinguishes between responses, aiding in the interpretation of any trends or relationships."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Hypothesis Testing***"
      ],
      "metadata": {
        "id": "GpxF2WLneSTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previously Insured and Response Relationship:\n",
        "\n",
        "Hypothesis:\n",
        "\n",
        "\n",
        " **HO**: There is no association between Previously Insured status and Response.\n",
        "\n",
        " **Ha**: There is an association between Previously Insured status and Response."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "contingency_table = pd.crosstab(df['Previously_Insured'], df['Response'])\n",
        "print(\"Contingency Table:\")\n",
        "print(contingency_table)"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print(f'Chi-square statistic: {chi2}')\n",
        "print(f'p-value: {p}')\n",
        "print(f'Degrees of freedom: {dof}')\n",
        "print(\"Expected frequencies:\")\n",
        "print(expected)\n"
      ],
      "metadata": {
        "id": "xL0A-NtP8KyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.05\n",
        "\n",
        "if p < alpha:\n",
        "    print(\"Reject the null hypothesis (H0). There is a significant association between Previously Insured status and Response.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis (H0). There is no significant association between Previously Insured status and Response.\")"
      ],
      "metadata": {
        "id": "0d7yEzDS8NwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used the Chi-square test of independence for this hypothesis because it is a statistical test specifically designed to determine whether there is a significant association between two categorical variables. In our case, the two categorical variables are \"Previously Insured\" and \"Response\"."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Dependent and Independent Variable***"
      ],
      "metadata": {
        "id": "Tf_gOsO-_gfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.drop('Response',axis=1)\n",
        "y=df['Response']"
      ],
      "metadata": {
        "id": "b17dGRsO_fp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X,y)"
      ],
      "metadata": {
        "id": "o0TWAJlQ_9vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "20IfEN7FAJMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "#Let's Try Kmeans Algorithm\n",
        "kmeans=KMeans(n_clusters=2, random_state=600).fit(X)\n",
        "\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cluster']=kmeans.labels_\n",
        "df"
      ],
      "metadata": {
        "id": "bvkj8dTXAj60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cluster'].value_counts()"
      ],
      "metadata": {
        "id": "7Kz0jsTwA2XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Kmeans accuracy: ', accuracy_score(df['Response'], df['cluster']))\n",
        "print('Kmeans f1_score: ', f1_score(df['Response'], df['cluster']))"
      ],
      "metadata": {
        "id": "GY1bw3RWA6kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Splitting the Data Into Train and Test***"
      ],
      "metadata": {
        "id": "QtR1HshgBGns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "40JYwxB_BNc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=240)"
      ],
      "metadata": {
        "id": "txQYy4w4BSbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "model = LogisticRegression(random_state=666)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(X_test)\n",
        "print('Simple Logistic Regression accuracy: ', accuracy_score(y_test, y_pred))\n",
        "print('Simple Logistic Regression f1_score: ', f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "9eNb012aBuks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_confusion_matrix(y_test, y_pred):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax, fmt='g')\n",
        "\n",
        "    ax.set_xlabel('Predicted labels')\n",
        "    ax.set_ylabel('True labels')"
      ],
      "metadata": {
        "id": "kJPnfv83B-f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_test,y_pred)"
      ],
      "metadata": {
        "id": "IKzvKyBTCHBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By Using Logistic Regression We can see we are getting Accuracy score of 88% and F1 score of 0.095, the we have used confusion matrix where we can see the True negatives are 98890, True positives are 776, False positive is 13237 and False negative is 1430."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Let's Try another Model*"
      ],
      "metadata": {
        "id": "ZL1U_zs8DC6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "# Fit the Algorithm\n",
        "rf_model.fit(X_train,y_train)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "y_pred_rf=rf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "ALUXR8FQD3y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Simple Random Forest accuracy: ', accuracy_score(y_test, y_pred_rf))\n",
        "print('Simple Random Forest f1_score: ', f1_score(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "oOzkZrFCEDWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#As th Dataset is very big we are taking samples of the data\n",
        "X_train_sample, _, y_train_sample, _ = train_test_split(\n",
        "    X_train, y_train, train_size=0.2, random_state=42  # 20% of the training data\n",
        ")"
      ],
      "metadata": {
        "id": "uPzJO19marU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "\n",
        "# Define the parameter grid\n",
        "param_dist = {\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'min_samples_split':randint(2,10),\n",
        "    'n_estimators': randint(10, 50)\n",
        "}\n",
        "\n",
        "# Set up the random search with 3-fold cross-validation\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=RandomForestClassifier(),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,  # Number of iterations\n",
        "    cv=3,  # Number of folds for cross-validation\n",
        "    verbose=2,\n",
        "    n_jobs=-1,\n",
        "    random_state=400,\n",
        "    scoring='accuracy'\n",
        ")"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_search.fit(X_train_sample, y_train_sample)"
      ],
      "metadata": {
        "id": "c0pfkj-KFbI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = random_search.best_params_\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "print(\"Best Parameters: \", best_params)"
      ],
      "metadata": {
        "id": "UkQvOC7TFfRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=random_search.predict(X_test)"
      ],
      "metadata": {
        "id": "kDkCGx5ybslI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_pred,y_test)"
      ],
      "metadata": {
        "id": "qyHPjMYCb2kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "i have used RandomizedSearchCV for hyperparameter tunning, where i have passed some parameters like, n_estimators, max_features,min_samples_split,min_samples_leaf, and as the Dataset is very Large it would take so much time for execution, i have took out sample of the Training data from X_train and y_train."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The application of hyperparameter tuning using RandomizedSearchCV has resulted in a noticeable improvement in the model's accuracy. Specifically, the accuracy increased by 0.0107, which corresponds to a 1.07% improvement. This demonstrates the value of hyperparameter optimization in enhancing the performance of machine learning models**.\n",
        "\n",
        "**The following steps were taken to achieve this improvement**:\n",
        "\n",
        "**Defined a parameter grid for the Random Forest classifier**.\n",
        "**Utilized RandomizedSearchCV to find the optimal hyperparameters using cross-validation**.\n",
        "**Retrained the model using the best hyperparameters found**.\n",
        "**Evaluated the accuracy of the optimized model on the test set**"
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using accuracy as an evaluation metric is a good starting point, but depending on the business context and the specific problem you're addressing, there are other metrics that might provide more insight into the model's performance."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the provided information, the model chosen for the final prediction is the Random Forest classifier with hyperparameter tuning using RandomizedSearchCV. The reason for this choice is that it achieved the highest accuracy among the models you evaluated. Here is a summary of the accuracies:\n",
        "\n",
        "Logistic Regression: 0.8717\n",
        "Random Forest (without hyperparameter tuning): 0.8659\n",
        "Random Forest (with hyperparameter tuning using RandomizedSearchCV): 0.8767"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Random Forest classifier with hyperparameter tuning was chosen as the final model due to its superior accuracy and ability to capture intricate patterns in the data. This model outperformed both Logistic Regression and the untuned Random Forest, making it the most suitable choice for the insurance cross-sell prediction task.\n",
        "\n",
        "**Business Impact**:\n",
        "\n",
        "**Increased Revenue**: By accurately identifying customers with a higher likelihood of purchasing additional insurance products, the company can target marketing campaigns more effectively, leading to increased cross-selling success rates and revenue generation.\n",
        "\n",
        "**Enhanced Customer Experience**: By offering relevant insurance products to existing customers based on their needs and preferences, the company can improve customer satisfaction and loyalty.\n",
        "\n",
        "**The developed machine learning model provides a valuable tool for insurance companies to optimize their cross-selling strategies and maximize revenue from existing customer bases**. **By leveraging advanced analytics and predictive modeling techniques, the company can gain actionable insights into customer behavior and preferences, ultimately driving business growth and competitive advantage in the insurance industry**."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}