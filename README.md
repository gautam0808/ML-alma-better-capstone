The objective of this project is to predict whether existing insurance customers will purchase a vehicle insurance policy. Utilizing a dataset containing customer demographics, policy details, and previous insurance status, the project involves data preprocessing, feature engineering, and developing predictive models. By applying Logistic Regression, Random Forest Classifier, and KMeans Clustering, and using hyperparameter tuning, the goal is to enhance prediction accuracy and help the insurance company effectively target potential buyers, thereby improving cross-selling opportunities.

Data Exploration and Preprocessing: The initial exploration of the data involved understanding the distribution and relationships within the dataset. Key preprocessing steps included handling missing values and encoding categorical variables. Categorical variables such as Gender, Vehicle_Age, and Vehicle_Damage were label-encoded, while variables like Region_Code and Policy_Sales_Channel were one-hot encoded to ensure compatibility with machine learning algorithms. Numerical features were standardized to bring all variables to a comparable scale.

Exploratory Data Analysis (EDA): EDA was conducted using visualizations to identify trends and patterns within the data. Histograms, bar charts, and heatmaps were used to visualize the distributions and correlations. Notable observations included:

Customers with Previously_Insured status were less likely to purchase vehicle insurance, which was confirmed through the Chi-square test of independence. Significant variation in Annual_Premium across different Region_Code values, justifying the need for feature engineering and hypothesis testing. Hypothesis Testing: A Chi-square test of independence was employed to examine the relationship between categorical variables such as Previously_Insured and Response. This test confirmed a significant association between the insurance status of customers and their likelihood of purchasing vehicle insurance, guiding feature selection for the predictive model.

Feature Engineering: To enhance model performance, categorical data was encoded into numerical formats. Label encoding and one-hot encoding were applied as appropriate. This transformation ensured that the machine learning algorithms could effectively process and interpret the data.

Model Development: Several machine learning models were developed and evaluated, including Logistic Regression, KMeans Clustering, and Random Forest Classifier. The dataset was split into training and testing sets to evaluate the performance of each model. Performance metrics such as accuracy, precision, recall, and F1-score were utilized to assess the effectiveness of the models. Hyperparameter tuning techniques, including grid search and random search, were employed to optimize model parameters and improve performance.

Results: The Random Forest Classifier achieved the highest performance, with significant improvements observed after hyperparameter tuning. The Logistic Regression model also provided valuable insights due to its interpretability, while KMeans Clustering was explored for customer segmentation, offering a different perspective on the data.

Conclusion: This project successfully developed a predictive model for insurance cross-sell, leveraging machine learning to identify key factors influencing customer decisions. The findings can help the insurance company strategically target potential customers, enhancing cross-selling opportunities and overall profitability. Future work could involve incorporating additional features, such as customer interaction data, and exploring more advanced modeling techniques to further refine the predictions and improve the model's accuracy

Based on the provided information, the model chosen for the final prediction is the Random Forest classifier with hyperparameter tuning using RandomizedSearchCV. The reason for this choice is that it achieved the highest accuracy among the models you evaluated. Here is a summary of the accuracies:

Logistic Regression: 0.8717 Random Forest (without hyperparameter tuning): 0.8659 Random Forest (with hyperparameter tuning using RandomizedSearchCV): 0.8767
